{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Wikipedia page for November 15...\n",
      "Found 6 people\n",
      "qpp1115.xml\n",
      "\n",
      "Sample of first 5 entries:\n",
      "1. 459 - Bʼutz Aj Sak Chiik | Mayan king (died 501)\n",
      "2. 1316 - John I | king of France and Navarre (died 1316)\n",
      "3. 1397 - Nicholas V | pope of the Catholic Church (died 1455)\n",
      "4. 1498 - Eleanor of Austria | queen of Portugal and France (died 1558)\n",
      "5. 1511 - Johannes Secundus | Dutch poet and author (died 1536)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_wikipedia_page(date_month, date_day):\n",
    "    \"\"\"Get Wikipedia page for a specific date\"\"\"\n",
    "    url = f\"https://en.wikipedia.org/wiki/{date_month}_{date_day}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_births(html_content):\n",
    "    \"\"\"Parse the births section from Wikipedia HTML\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find \"Births\" section\n",
    "    for header in soup.find_all(['h2', 'h3']):\n",
    "        if 'Births' in header.get_text():\n",
    "            # Get next <ul> after the header\n",
    "            ul = header.find_next('ul')\n",
    "            return ul\n",
    "    return None\n",
    "\n",
    "def extract_person_info(li_text):\n",
    "    \"\"\"Extract year, name, and occupation from list item text\"\"\"\n",
    "    parts = li_text.split(' – ', 1)\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "    \n",
    "    year = parts[0].strip()\n",
    "    rest = parts[1].strip()\n",
    "    \n",
    "    # Extract name (before first comma)\n",
    "    if ',' in rest:\n",
    "        name, occupation = rest.split(',', 1)\n",
    "        occupation = occupation.strip()\n",
    "    else:\n",
    "        name = rest\n",
    "        occupation = \"\"\n",
    "    \n",
    "    # Clean name - remove citations like [1], [2]\n",
    "    name = name.split('[')[0].strip()\n",
    "    \n",
    "    # Format name: replace spaces with underscores, keep commas\n",
    "    formatted_name = name.replace(' ', '_')\n",
    "    \n",
    "    return year, formatted_name, occupation\n",
    "\n",
    "def create_xml_output(people_data):\n",
    "    \"\"\"Create XML in the specified format\"\"\"\n",
    "    root = ET.Element(\"persons\")\n",
    "    root.set(\"day\", \"11-14\")\n",
    "    root.set(\"сomm\", \"создан 01.12 К.А.\")\n",
    "    \n",
    "    for year, name, occupation in people_data:\n",
    "        psn = ET.SubElement(root, \"psn\")\n",
    "        psn.set(\"y\", year)\n",
    "        psn.set(\"h\", name)\n",
    "        if occupation:\n",
    "            psn.set(\"p\", occupation)\n",
    "    \n",
    "    # Convert to string\n",
    "    xml_str = '<?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n'\n",
    "    xml_str += ET.tostring(root, encoding='unicode')\n",
    "    \n",
    "    return xml_str\n",
    "\n",
    "def main():\n",
    "    # Set date (November 14)\n",
    "    month = \"November\"\n",
    "    day = \"15\"\n",
    "    \n",
    "    print(f\"Getting Wikipedia page for {month} {day}...\")\n",
    "    \n",
    "    # Get Wikipedia page\n",
    "    html = get_wikipedia_page(month, day)\n",
    "    if not html:\n",
    "        print(\"Failed to get Wikipedia page\")\n",
    "        return\n",
    "    \n",
    "    # Parse births section\n",
    "    births_list = parse_births(html)\n",
    "    if not births_list:\n",
    "        print(\"No births section found\")\n",
    "        return\n",
    "    \n",
    "    # Extract people data\n",
    "    people_data = []\n",
    "    \n",
    "    for li in births_list.find_all('li'):\n",
    "        li_text = li.get_text().strip()\n",
    "        \n",
    "        # Skip empty items\n",
    "        if not li_text:\n",
    "            continue\n",
    "        \n",
    "        # Extract info\n",
    "        result = extract_person_info(li_text)\n",
    "        if result:\n",
    "            people_data.append(result)\n",
    "    \n",
    "    print(f\"Found {len(people_data)} people\")\n",
    "    \n",
    "    # Create XML\n",
    "    xml_output = create_xml_output(people_data)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(\"qpp1115.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(xml_output)\n",
    "    \n",
    "    print(\"qpp1115.xml\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nSample of first 5 entries:\")\n",
    "    for i, (year, name, occupation) in enumerate(people_data[:1000]):\n",
    "        occupation_display = f\" | {occupation}\" if occupation else \"\"\n",
    "        print(f\"{i+1}. {year} - {name.replace('_', ' ')}{occupation_display}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
