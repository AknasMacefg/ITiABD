{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a564d5f",
   "metadata": {},
   "source": [
    "#  Forward pass\n",
    "\n",
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы: \n",
    "* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann \n",
    "* https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
    "* https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "* https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n",
    "* https://kidger.site/thoughts/jaxtyping/\n",
    "* https://github.com/patrick-kidger/torchtyping/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd663",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7ad9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtyping import TensorType, patch_typeguard\n",
    "from typeguard import typechecked\n",
    "import torch as th\n",
    "\n",
    "Scalar = TensorType[()]\n",
    "patch_typeguard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d01a9",
   "metadata": {
    "id": "_2ArJn_nsdZC"
   },
   "source": [
    "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте нейрон с заданными весами `weights` и `bias`. Пропустите вектор `inputs` через нейрон и выведите результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc1b50d5",
   "metadata": {
    "id": "f4agkY9WqPwe"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_features: int, bias: float):\n",
    "        # <создать атрибуты объекта weights и bias>\n",
    "        self.weights: TensorType[n_features] = th.randn(n_features)\n",
    "        print(self.weights)\n",
    "        self.bias: float = bias\n",
    "\n",
    "    def forward(self, inputs: TensorType[\"n_features\"]) -> Scalar:\n",
    "        return th.dot(inputs, self.weights) + self.bias # <реализовать логику нейрона>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f299f7",
   "metadata": {
    "id": "HJRkSkHHsb7u"
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "inputs = th.tensor([1.0, 2.0, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc5e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8616,  0.9866, -0.0651,  0.4107])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.2826)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = Neuron(4, True)\n",
    "neuron.forward(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5fe51",
   "metadata": {
    "id": "B9kngE6Fxs9D"
   },
   "source": [
    "2\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ReLU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
    "\n",
    "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679f4e5",
   "metadata": {
    "id": "jZLvMRByxSTC"
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    @typechecked\n",
    "    def forward(self, inputs: TensorType[\"n_features\"]) -> TensorType[\"n_features\"]:\n",
    "         # <реализовать логику ReLU>\n",
    "        return th.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a16748",
   "metadata": {
    "id": "EY-k3eEs0f7f"
   },
   "source": [
    "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь MSE:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
    "где $Y_i$ - правильный ответ для примера $i$, $\\hat{Y_i}$ - предсказание модели для примера $i$, $n$ - количество примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e046dfa6",
   "metadata": {
    "id": "f9-wdj5Tz-br"
   },
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    @typechecked\n",
    "    def forward(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"]) -> Scalar:\n",
    "        return (y_pred - y_true).square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e686f8b8",
   "metadata": {
    "id": "NAyuDU9F1Vuz"
   },
   "outputs": [],
   "source": [
    "y_pred = th.tensor([1.0, 3.0, 5.0])\n",
    "y_true = th.tensor([2.0, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6470799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = MSELoss()\n",
    "l = l.forward(y_pred, y_true)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b6d63",
   "metadata": {},
   "source": [
    "## Задачи для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e742b",
   "metadata": {
    "id": "0J2RM8f5wP33"
   },
   "source": [
    "### Cоздание полносвязных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe867c",
   "metadata": {
    "id": "OQ2OxH4_vBLu"
   },
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения) и опциональным вектором смещения. \n",
    "\n",
    "$$y = xW^T + b$$\n",
    "\n",
    "Пропустите вектор `inputs` через слой и выведите результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "680571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_neurons: int, n_features: int, bias: bool = False) -> None:\n",
    "        self.w = th.randn(n_features, n_neurons)\n",
    "        self.b = th.randn(n_neurons)\n",
    "\n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"n_neurons\"]:\n",
    "        return inputs @ self.w + self.b\n",
    "    #return th.mm(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad52a4f",
   "metadata": {
    "id": "IPG4UqL4wajI"
   },
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Используя решение предыдущей задачи, создайте 2 полносвязных слоя и пропустите тензор `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выберите произвольно, количество нейронов во втором слое выберите так, чтобы результатом прогона являлась матрица `batch_size x 7`. \n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "n_features = 4\n",
    "\n",
    "l1 = Linear(10, n_features)\n",
    "l2 = Linear(7, 10)\n",
    "\n",
    "inputs = th.randn(batch_size, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6370196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = l1.forward(inputs)\n",
    "y2 = l2.forward(y1)\n",
    "y2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89bb8e",
   "metadata": {
    "id": "cRVH_2K7xTBC"
   },
   "source": [
    "### Создание функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c912a6",
   "metadata": {
    "id": "puExCWiKyTtb"
   },
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации softmax:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
    "\n",
    "$$\\overrightarrow{x} = (x_1, ..., x_J)$$\n",
    "\n",
    "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров. Функция должна применяться переданной на вход матрице построчно.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec4062",
   "metadata": {
    "id": "fXNcFlqqyKHl"
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
    "         # <реализовать логику Softmax>\n",
    "        exps = th.exp(inputs - th.max(inputs, dim=-1, keepdim=True).values)\n",
    "        return exps / th.sum(exps, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8acbae",
   "metadata": {
    "id": "vxVK2TYez_Ye"
   },
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ELU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
    "\n",
    "Создайте матрицу размера 4x3, заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELU:\n",
    "    def __init__(self, alpha: float) -> None:\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
    "        # <реализовать логику ELU>\n",
    "        return th.where(inputs > 0, inputs, self.alpha * (th.exp(inputs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02fb0d",
   "metadata": {
    "id": "0peh8r-20Pof"
   },
   "source": [
    "### Создание функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7e56a",
   "metadata": {
    "id": "uaR7rILd1eWR"
   },
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь CrossEntropyLoss:\n",
    "\n",
    "$$y_i = (y_{i,1},...,y_{i,k})$$ \n",
    "\n",
    "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
    "\n",
    "$$ CrossEntropyLoss = \\frac{1}{n}\\sum_{i=1}^{n}{L_i}$$\n",
    "где $y_i$ - вектор правильных ответов для примера $i$, $\\hat{y_i}$ - вектор предсказаний модели для примера $i$; $k$ - количество классов, $n$ - количество примеров в батче.\n",
    "\n",
    "Создайте полносвязный слой с 2 нейронами и прогнать через него батч `inputs`. Полученный результат пропустите через функцию активации Softmax. Посчитайте значение функции потерь, трактуя вектор `y` как вектор правильных ответов.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f683f102",
   "metadata": {
    "id": "hQl8pJsT3HcF"
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def forward(self, y_pred: TensorType[\"batch\", float], y_true: TensorType[\"batch\", int]):\n",
    "        # <реализовать логику функции потерь>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c82a1",
   "metadata": {
    "id": "fA6dbanf44_4"
   },
   "source": [
    "<p class=\"task\" id=\"6\"></p>\n",
    "\n",
    "6 Модифицируйте MSE, добавив L2-регуляризацию.\n",
    "\n",
    "$$MSE_R = MSE + \\lambda\\sum_{i=1}^{m}w_i^2$$\n",
    "\n",
    "где $\\lambda$ - коэффициент регуляризации; $w_i$ - веса модели.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f858a9",
   "metadata": {
    "id": "ADsZxD-h4_Os"
   },
   "outputs": [],
   "source": [
    "class MSERegularized:\n",
    "    def __init__(self, lambda_: float) -> None:\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def data_loss(\n",
    "            self, \n",
    "            y_pred: TensorType[\"batch\"], \n",
    "            y_true: TensorType[\"batch\"],\n",
    "    ) -> Scalar:\n",
    "        # <подсчет первого слагаемого из формулы>\n",
    "        pass\n",
    "\n",
    "    def reg_loss(self, weights: TensorType[\"batch\", 1])  -> Scalar:\n",
    "        # <подсчет второго слагаемого из формулы>\n",
    "        pass\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        y_pred: TensorType[\"batch\"], \n",
    "        y_true: TensorType[\"batch\"], \n",
    "        weights: TensorType[\"batch\", 1],\n",
    "    ) -> Scalar:\n",
    "        return self.data_loss(y_pred, y_true) + lambda_ * self.reg_loss(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
